---
abstract: 'Second order stochastic optimizers allow parameter update step size and
  direction to adapt to loss curvature, but have traditionally required too much memory
  and compute for deep learning. Recently, Shampoo [Gupta et al., 2018] introduced
  a Kronecker factored preconditioner to reduce these requirements: it is used for
  large deep models [Anil et al., 2020] and in production [Anil et al., 2022]. However,
  it takes inverse matrix roots of ill-conditioned matrices. This requires 64-bit
  precision, imposing strong hardware constraints. In this paper, we propose a novel
  factorization, Kronecker Approximation-Domination (KrAD). Using KrAD, we update
  a matrix that directly approximates the inverse empirical Fisher matrix (like full
  matrix AdaGrad), avoiding inversion and hence 64-bit precision. We then propose
  KrADagrad , with similar computational costs to Shampoo and the same regret. Synthetic
  ill-conditioned experiments show improved performance over Shampoo for 32-bit precision,
  while for several real datasets we have comparable or better generalization.'
openreview: EvTTqBq2yBN
software: http://github.com/jonathanmei/kradagrad
title: 'KrADagrad: Kronecker approximation-domination gradient preconditioned stochastic
  optimization'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: mei23a
month: 0
tex_title: "{KrADagrad}: {K}ronecker approximation-domination gradient preconditioned
  stochastic optimization"
firstpage: 1412
lastpage: 1422
page: 1412-1422
order: 1412
cycles: false
bibtex_author: Mei, Jonathan and Moreno, Alexander and Walters, Luke
author:
- given: Jonathan
  family: Mei
- given: Alexander
  family: Moreno
- given: Luke
  family: Walters
date: 2023-07-02
address:
container-title: Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial
  Intelligence
volume: '216'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 2
pdf: https://proceedings.mlr.press/v216/mei23a/mei23a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v216/mei23a/mei23a-supp.pdf
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
