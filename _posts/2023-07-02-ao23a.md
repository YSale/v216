---
abstract: Proper confidence calibration of deep neural networks is essential for reliable
  predictions in safety-critical tasks. Miscalibration can lead to model over-confidence
  and/or under-confidence; i.e., the model’s confidence in its prediction can be greater
  or less than the model’s accuracy. Recent studies have highlighted the over-confidence
  issue by introducing calibration techniques and demonstrated success on various
  tasks. However, miscalibration through under-confidence has not yet to receive much
  attention. In this paper, we address the necessity of paying attention to the under-confidence
  issue. We first introduce a novel metric, a miscalibration score, to identify the
  overall and class-wise calibration status, including being over or under-confident.
  Our proposed metric reveals the pitfalls of existing calibration techniques, where
  they often overly calibrate the model and worsen under-confident predictions. Then
  we utilize the class-wise miscalibration score as a proxy to design a calibration
  technique that can tackle both over and under-confidence. We report extensive experiments
  that show our proposed methods substantially outperforming existing calibration
  techniques. We also validate our proposed calibration technique on an automatic
  failure detection task with a risk-coverage curve, reporting that our methods improve
  failure detection as well as trustworthiness of the model. The code are available
  at \url{https://github.com/AoShuang92/miscalibration_TS}.
openreview: hsPsoJWZWo
title: 'Two Sides of Miscalibration: Identifying Over and Under-Confidence Prediction
  for Network Calibration'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ao23a
month: 0
tex_title: 'Two Sides of Miscalibration: Identifying Over and Under-Confidence Prediction
  for Network Calibration'
firstpage: 77
lastpage: 87
page: 77-87
order: 77
cycles: false
bibtex_author: Ao, Shuang and Rueger, Stefan and Siddharthan, Advaith
author:
- given: Shuang
  family: Ao
- given: Stefan
  family: Rueger
- given: Advaith
  family: Siddharthan
date: 2023-07-02
address:
container-title: Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial
  Intelligence
volume: '216'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 2
pdf: https://proceedings.mlr.press/v216/ao23a/ao23a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v216/ao23a/ao23a-supp.pdf
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
