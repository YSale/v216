---
abstract: Gradient inversion attack enables recovery of training samples from model
  gradients in federated learning (FL), and constitutes a serious threat to data privacy.
  To mitigate this vulnerability, prior work proposed both principled defenses based
  on differential privacy, as well as heuristic defenses based on gradient compression
  as countermeasures. These defenses have so far been very effective, in particular
  those based on gradient compression that allow the model to maintain high accuracy
  while greatly reducing the effectiveness of attacks. In this work, we argue that
  such findings underestimate the privacy risk in FL. As a counterexample, we show
  that existing defenses can be broken by a simple adaptive attack, where a model
  trained on auxiliary data is able to invert gradients on both vision and language
  tasks.
openreview: EbzSHEQUES
title: 'Learning To Invert: Simple Adaptive Attacks for Gradient Inversion in Federated
  Learning'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wu23a
month: 0
tex_title: 'Learning To Invert: Simple Adaptive Attacks for Gradient Inversion in
  Federated Learning'
firstpage: 2293
lastpage: 2303
page: 2293-2303
order: 2293
cycles: false
bibtex_author: Wu, Ruihan and Chen, Xiangyu and Guo, Chuan and Weinberger, Kilian
  Q.
author:
- given: Ruihan
  family: Wu
- given: Xiangyu
  family: Chen
- given: Chuan
  family: Guo
- given: Kilian Q.
  family: Weinberger
date: 2023-07-02
address:
container-title: Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial
  Intelligence
volume: '216'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 2
pdf: https://proceedings.mlr.press/v216/wu23a/wu23a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v216/wu23a/wu23a-supp.pdf
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
