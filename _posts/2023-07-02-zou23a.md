---
abstract: Mixup is a popular data augmentation technique for training deep neural
  networks where additional samples are generated by linearly interpolating pairs
  of inputs and their labels. This technique is known to improve the generalization
  performance in many learning paradigms and applications. In this work, we first
  analyze Mixup and show that it implicitly regularizes infinitely many directional
  derivatives of all orders. Based on this new insight, we propose an improved version
  of Mixup, theoretically justified to deliver better generalization performance than
  the vanilla Mixup. To demonstrate the effectiveness of the proposed method, we conduct
  experiments across various domains such as images, tabular data, speech, and graphs.
  Our results show that the proposed method improves Mixup across multiple datasets
  using a variety of architectures, for instance, exhibiting an improvement over Mixup
  by 0.8% in ImageNet top-1 accuracy.
openreview: dJwDehsDDU
title: 'MixupE: Understanding and improving Mixup from directional derivative perspective'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zou23a
month: 0
tex_title: "{MixupE}: Understanding and improving Mixup from directional derivative
  perspective"
firstpage: 2597
lastpage: 2607
page: 2597-2607
order: 2597
cycles: false
bibtex_author: Zou, Yingtian and Verma, Vikas and Mittal, Sarthak and Tang, Wai Hoh
  and Pham, Hieu and Kannala, Juho and Bengio, Yoshua and Solin, Arno and Kawaguchi,
  Kenji
author:
- given: Yingtian
  family: Zou
- given: Vikas
  family: Verma
- given: Sarthak
  family: Mittal
- given: Wai Hoh
  family: Tang
- given: Hieu
  family: Pham
- given: Juho
  family: Kannala
- given: Yoshua
  family: Bengio
- given: Arno
  family: Solin
- given: Kenji
  family: Kawaguchi
date: 2023-07-02
address:
container-title: Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial
  Intelligence
volume: '216'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 2
pdf: https://proceedings.mlr.press/v216/zou23a/zou23a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v216/zou23a/zou23a-supp.pdf
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
