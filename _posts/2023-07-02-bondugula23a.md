---
abstract: High-dimensional data is common in multiple areas, such as health care and
  genomics, where the number of features can be tens of thousands. In such scenarios,
  the large number of features often leads to inefficient learning. Constraint generation
  methods have recently enabled efficient learning of L1-regularized support vector
  machines (SVMs). In this paper, we leverage such methods to obtain an efficient
  learning algorithm for the recently proposed minimax risk classifiers (MRCs). The
  proposed iterative algorithm also provides a sequence of worst-case error probabilities
  and performs feature selection. Experiments on multiple high-dimensional datasets
  show that the proposed algorithm is efficient in high-dimensional scenarios. In
  addition, the worst-case error probability provides useful information about the
  classifier performance, and the features selected by the algorithm are competitive
  with the state-of-the-art.
openreview: nqu-dr7-y5
software: https://github.com/MachineLearningBCAM/MRCpy
title: Efficient Learning of Minimax Risk Classifiers in High Dimensions
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: bondugula23a
month: 0
tex_title: Efficient Learning of Minimax Risk Classifiers in High Dimensions
firstpage: 206
lastpage: 215
page: 206-215
order: 206
cycles: false
bibtex_author: Bondugula, Kartheek and Mazuelas, Santiago and P\'{e}rez, Aritz
author:
- given: Kartheek
  family: Bondugula
- given: Santiago
  family: Mazuelas
- given: Aritz
  family: PÃ©rez
date: 2023-07-02
address:
container-title: Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial
  Intelligence
volume: '216'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 2
pdf: https://proceedings.mlr.press/v216/bondugula23a/bondugula23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
