---
abstract: One of the objectives of continual learning is to prevent catastrophic forgetting
  in learning multiple tasks sequentially, and the existing solutions have been driven
  by the conceptualization of the plasticity-stability dilemma. However, the convergence
  of continual learning for each sequential task is less studied so far. In this paper,
  we provide a convergence analysis of memory-based continual learning with stochastic
  gradient descent and empirical evidence that training current tasks causes the cumulative
  degradation of previous tasks. We propose an adaptive method for nonconvex continual
  learning (NCCL), which adjusts step sizes of both previous and current tasks with
  the gradients. The proposed method can achieve the same convergence rate as the
  SGD method when the catastrophic forgetting term which we define in the paper is
  suppressed at each iteration. Further, we demonstrate that the proposed algorithm
  improves the performance of continual learning over existing methods for several
  image classification tasks.
openreview: 91OQsvbMGA
title: On the Convergence of Continual Learning with Adaptive Methods
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: han23a
month: 0
tex_title: On the Convergence of Continual Learning with Adaptive Methods
firstpage: 809
lastpage: 818
page: 809-818
order: 809
cycles: false
bibtex_author: Han, Seungyub and Kim, Yeongmo and Cho, Taehyun and Lee, Jungwoo
author:
- given: Seungyub
  family: Han
- given: Yeongmo
  family: Kim
- given: Taehyun
  family: Cho
- given: Jungwoo
  family: Lee
date: 2023-07-02
address:
container-title: Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial
  Intelligence
volume: '216'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 2
pdf: https://proceedings.mlr.press/v216/han23a/han23a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v216/han23a/han23a-supp.pdf
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
