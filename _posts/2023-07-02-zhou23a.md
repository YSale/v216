---
abstract: Reinforcement learning algorithms have achieved remarkable success in acquiring
  behavioral skills directly from pixel inputs. However, their application in real-world
  scenarios presents challenges due to their sensitivity to visual distractions (e.g.,
  changes in viewpoint and light). A key factor contributing to this challenge is
  that the learned representations often suffer from overfitting task-irrelevant information.
  By comparing several representation learning methods, we find that the key to alleviating
  overfitting in representation learning is to choose proper prediction targets. Motivated
  by our comparison, we propose a novel representation learning approach—namely, reward
  sequence prediction (RSP)—that uses reward sequences or their transforms (e.g.,
  discrete time Fourier transform) as prediction targets. RSP can efficiently learn
  robust representations as reward sequences rarely contain task-irrelevant information
  while providing a large number of supervised signals to accelerate representation
  learning. An appealing feature is that RSP makes no assumption about the type of
  distractions and thus can improve performance even when multiple types of distractions
  exist. We evaluate our approach in Distracting Control Suite. Experiments show that
  our method achieves state-of-the-art sample efficiency and generalization ability
  in tasks with distractions.
openreview: AYqrogCCKlz
title: Learning robust representation for reinforcement learning with distractions
  by reward sequence prediction
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhou23a
month: 0
tex_title: Learning robust representation for reinforcement learning with distractions
  by reward sequence prediction
firstpage: 2551
lastpage: 2562
page: 2551-2562
order: 2551
cycles: false
bibtex_author: Zhou, Qi and Wang, Jie and Liu, Qiyuan and Kuang, Yufei and Zhou, Wengang
  and Li, Houqiang
author:
- given: Qi
  family: Zhou
- given: Jie
  family: Wang
- given: Qiyuan
  family: Liu
- given: Yufei
  family: Kuang
- given: Wengang
  family: Zhou
- given: Houqiang
  family: Li
date: 2023-07-02
address:
container-title: Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial
  Intelligence
volume: '216'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 2
pdf: https://proceedings.mlr.press/v216/zhou23a/zhou23a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v216/zhou23a/zhou23a-supp.pdf
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
