---
abstract: The Right to Explanation is an important regulatory principle that allows
  individuals to request actionable explanations for algorithmic decisions. However,
  several technical challenges arise when providing such actionable explanations in
  practice. For instance, models are periodically retrained to handle dataset shifts.
  This process may invalidate some of the previously prescribed explanations, thus
  rendering them unactionable. But, it is unclear if and when such invalidations occur,
  and what factors determine explanation stability i.e., if an explanation remains
  unchanged amidst model retraining due to dataset shifts. In this paper, we address
  the aforementioned gaps and provide one of the first theoretical and empirical characterizations
  of the factors influencing explanation stability. To this end, we conduct rigorous
  theoretical analysis to demonstrate that model curvature, weight decay parameters
  while training, and the magnitude of the dataset shift are key factors that determine
  the extent of explanation (in)stability. Extensive experimentation with real-world
  datasets not only validates our theoretical results, but also demonstrates that
  the aforementioned factors dramatically impact the stability of explanations produced
  by various state-of-the-art methods.
openreview: i04gl3OykJ
software: https://github.com/AI4LIFE-GROUP/robust-grads
title: On Minimizing the Impact of Dataset Shifts on Actionable Explanations
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: meyer23a
month: 0
tex_title: On Minimizing the Impact of Dataset Shifts on Actionable Explanations
firstpage: 1434
lastpage: 1444
page: 1434-1444
order: 1434
cycles: false
bibtex_author: Meyer, Anna P. and Ley, Dan and Srinivas, Suraj and Lakkaraju, Himabindu
author:
- given: Anna P.
  family: Meyer
- given: Dan
  family: Ley
- given: Suraj
  family: Srinivas
- given: Himabindu
  family: Lakkaraju
date: 2023-07-02
address:
container-title: Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial
  Intelligence
volume: '216'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 2
pdf: https://proceedings.mlr.press/v216/meyer23a/meyer23a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v216/meyer23a/meyer23a-supp.pdf
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
