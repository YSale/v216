---
abstract: In many real-world problems, the learning agent needs to learn a problemâ€™s
  abstractions and solution simultaneously. However, most such abstractions need to
  be designed and refined by hand for different problems and domains of application.
  This paper presents a novel top-down approach for constructing state abstractions
  while carrying out reinforcement learning (RL). Starting with state variables and
  a simulator, it presents a novel domain-independent approach for dynamically computing
  an abstraction based on the dispersion of temporal difference errors in abstract
  states as the agent continues acting and learning. Extensive empirical evaluation
  on multiple domains and problems shows that this approach automatically learns semantically
  rich abstractions that are finely-tuned to the problem, yield strong sample efficiency,
  and result in the RL agent significantly outperforming existing approaches.
openreview: Z8_-LjXPKNe
title: Conditional abstraction trees for sample-efficient reinforcement learning
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: dadvar23a
month: 0
tex_title: Conditional abstraction trees for sample-efficient reinforcement learning
firstpage: 485
lastpage: 495
page: 485-495
order: 485
cycles: false
bibtex_author: Dadvar, Mehdi and Nayyar, Rashmeet Kaur and Srivastava, Siddharth
author:
- given: Mehdi
  family: Dadvar
- given: Rashmeet Kaur
  family: Nayyar
- given: Siddharth
  family: Srivastava
date: 2023-07-02
address:
container-title: Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial
  Intelligence
volume: '216'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 2
pdf: https://proceedings.mlr.press/v216/dadvar23a/dadvar23a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v216/dadvar23a/dadvar23a-supp.pdf
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
