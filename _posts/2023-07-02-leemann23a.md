---
abstract: Interest in understanding and factorizing learned embedding spaces through
  conceptual explanations is steadily growing. When no human concept labels are available,
  concept discovery methods search trained embedding spaces for interpretable concepts
  like object shape or color that can provide post-hoc explanations for decisions.
  Unlike previous work, we argue that concept discovery should be identifiable, meaning
  that a number of known concepts can be provably recovered to guarantee reliability
  of the explanations. As a starting point, we explicitly make the connection between
  concept discovery and classical methods like Principal Component Analysis and Independent
  Component Analysis by showing that they can recover independent concepts under non-Gaussian
  distributions. For dependent concepts, we propose two novel approaches that exploit
  functional compositionality properties of image-generating processes. Our provably
  identifiable concept discovery methods substantially outperform competitors on a
  battery of experiments including hundreds of trained models and dependent concepts,
  where they exhibit up to 29 % better alignment with the ground truth. Our results
  highlight the strict conditions under which reliable concept discovery without human
  labels can be guaranteed and provide a formal foundation for the domain. Our code
  is available online.
openreview: bRunhpBSuX
title: When are post-hoc conceptual explanations identifiable?
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: leemann23a
month: 0
tex_title: When are post-hoc conceptual explanations identifiable?
firstpage: 1207
lastpage: 1218
page: 1207-1218
order: 1207
cycles: false
bibtex_author: Leemann, Tobias and Kirchhof, Michael and Rong, Yao and Kasneci, Enkelejda
  and Kasneci, Gjergji
author:
- given: Tobias
  family: Leemann
- given: Michael
  family: Kirchhof
- given: Yao
  family: Rong
- given: Enkelejda
  family: Kasneci
- given: Gjergji
  family: Kasneci
date: 2023-07-02
address:
container-title: Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial
  Intelligence
volume: '216'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 2
pdf: https://proceedings.mlr.press/v216/leemann23a/leemann23a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v216/leemann23a/leemann23a-supp.pdf
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
