---
abstract: We propose two  Thompson Sampling-like, model-based learning algorithms  for
  episodic Markov decision processes (MDPs) with a finite time horizon. Our proposed
  algorithms are inspired by Optimistic Thompson Sampling (O-TS), empirically studied
  in Chapelle and Li [2011], May et al. [2012] for stochastic multi-armed bandits.
  The key idea for the original O-TS is to clip the posterior distribution in an optimistic
  way  to ensure that the sampled models are always better than the empirical models.
  Both of our proposed algorithms are easy to implement and only need one posterior
  sample to construct an episode-dependent model. Our first  algorithm, Optimistic
  Thompson Sampling for MDPs (O-TS-MDP), achieves a $\widetilde{O} \left(\sqrt{AS^2H^4T}
  \right)$ regret bound, where $S$ is the size of the state space, $A$ is the size
  of the action space, $H$ is the number of time-steps per episode and $T$ is the
  number of episodes. Our second algorithm, Optimistic Thompson Sampling plus for
  MDPs (O-TS-MDP$^+$),  achieves the (near)-optimal $\widetilde{O} \left(\sqrt{ASH^3T}
  \right)$ regret bound by taking a more aggressive clipping strategy.  Since O-TS
  was only empirically studied previously, we derive regret bounds of O-TS for stochastic
  bandits. In addition, we propose,  O-TS-Bandit$^+$, a randomized version of UCB1
  [Auer et al., 2002], for stochastic bandits. Both O-TS and O-TS-Bandit$^+$ achieve
  the optimal $O\left(\frac{A\ln(T)}{\Delta} \right)$ problem-dependent regret bound,
  where $\Delta$ denotes the sub-optimality gap.
openreview: Bj8o6Qs-TVL
title: Optimistic Thompson Sampling-based algorithms for episodic reinforcement learning
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: hu23a
month: 0
tex_title: Optimistic {T}hompson Sampling-based algorithms for episodic reinforcement
  learning
firstpage: 890
lastpage: 899
page: 890-899
order: 890
cycles: false
bibtex_author: Hu, Bingshan and Zhang, Tianyue H. and Hegde, Nidhi and Schmidt, Mark
author:
- given: Bingshan
  family: Hu
- given: Tianyue H.
  family: Zhang
- given: Nidhi
  family: Hegde
- given: Mark
  family: Schmidt
date: 2023-07-02
address:
container-title: Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial
  Intelligence
volume: '216'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 2
pdf: https://proceedings.mlr.press/v216/hu23a/hu23a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v216/hu23a/hu23a-supp.pdf
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
